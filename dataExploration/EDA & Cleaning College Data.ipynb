{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 857,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_colwidth', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 858,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### read in college data as json file, drop unnecessary columns\n",
    "with open('/Users/kstern/ds/metis/Kevin/Projects/Luther/data/collegeData.json') as f:\n",
    "   data = json.load(f)\n",
    "df = pd.DataFrame(data)\n",
    "df = df.drop(['retry_times','id', 'download_slot', 'download_timeout', 'depth', 'download_latency'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 859,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1975, 42)"
      ]
     },
     "execution_count": 859,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAMPLE DATA\n",
    "\n",
    "{'nearestAirport': u'20 mile(s) from campus in Lexington', 'freshmanHousingGuaranteed': u'Freshmen are guaranteed housing', 'pctWithLoans': u'70%', 'numGrad': u'2,517', 'SATMath': u'483 average ', 'ACT': u'22 average ', 'classSize': u'2-9 students: 20% of classes', 'pctInternationalStudents': u'1.6% from 44 countries', 'nearestTrain': u'\\xa0', 'id': u'944', 'totalCost': [u'In-state: $22,014 ', u' Out-of-state: $31,792'], 'tuitionCost': [u'In-state: $9,296', u'Out-of-state: $19,074'], 'roomCost': [u'$9,018'], 'schoolColors': u'Maroon and white', 'sportsDivision': u'NCAA Division I', 'sororities': u'6% of women participate', 'averageSalary': u'Not reported', 'avgGPA': u'3.29', 'pctStudentsGraduatingin4Yrs': u'  23.6%', 'numUndergrad': u'14,327', 'nearestBus': u'1 mile(s) from campus in Richmond', 'otherCost': [u'$2,700'], 'numFaculty': u'Not reported', 'areaPop': u'32,550', 'campusSize': u'500 acres', 'download_slot': 'www.collegedata.com', 'coed': u'Yes', 'pctAdvancedStudy': u'Not reported', 'undergradMen': u'8,181 (57.1%)', 'download_timeout': 180.0, 'avgAge': u'23', 'SATReading': u'481 average ', 'gotFinancialNeed': u'7,775 (97.6%) of applicants with financial need', 'fraternities': u'   8% of men participate', 'avgIndebtness': u' $34,358', 'mascot': u'Colonel', 'bookCost': [u'$1,000'], 'avgAward': u'$10,962', 'admissionRate': u'71% of 10,215 applicants were admitted', 'name': u'Eastern Kentucky University', 'SATWriting': u'457 average ', 'url': u'https://www.collegedata.com/cs/data/college/college_pg01_tmpl.jhtml?schoolId=944', 'institutionType': u'Public', 'pctEmployedin6Mo': u'Not reported', 'depth': 6, 'download_latency': 2.5333781242370605, 'undergradWomen': u'8,181 (57.1%)'}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### if y is missing, drop the row. if many of the x values for that obs is missing, drop it. if one x is missing, and the rest of the column is fairly well populated, fill with local/global median/mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 860,
   "metadata": {},
   "outputs": [],
   "source": [
    "#When scraping the cost variables, I used .extract() rather than .extract_first() because some of the total/tuition\n",
    "#costs had in state and out-of-state values. I wasn't sure if this was also the case for the other costs so wanted\n",
    "#to explore. .extract() returns a list of values, and since I have decided to use the out-of-state cost for now, this\n",
    "#reassigns totalCost and tuitionCost to the out-of-state values for schools which had them. If they only had one value,\n",
    "#the cost remained the same.\n",
    "df['totalCost'][df.totalCost.str.len() == 2] = pd.DataFrame(df.loc[df.totalCost.str.len() == 2].totalCost.values.tolist(), index= df.loc[df.totalCost.str.len() == 2].index)[1]\n",
    "df['tuitionCost'][df.tuitionCost.str.len() == 2] = pd.DataFrame(df.loc[df.tuitionCost.str.len() == 2].tuitionCost.values.tolist(), index= df.loc[df.tuitionCost.str.len() == 2].index)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 861,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code brings the cost variables out of the list format and removes all non numeric characters\n",
    "costColumns = ['totalCost', 'tuitionCost', 'bookCost', 'roomCost', 'otherCost']\n",
    "\n",
    "for column in costColumns:\n",
    "    df[column] = df[column].apply(lambda x: ''.join(x))\n",
    "    df[column] = df[column].apply(lambda x: ''.join([c for c in x if c.isnumeric()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 862,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If the observation does not have a dependent variable, drop that record\n",
    "df.totalCost = df.totalCost.replace([\"\\u00a0\", \"Not reported\", 'Not available', ''], np.nan)\n",
    "df = df[df['totalCost'].notnull()]\n",
    "df.totalCost = pd.to_numeric(df.totalCost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 863,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the class size variable is brought in as a list of bins with the % each bin is represented\n",
    "#e.g. 2-9 students: 39% of classes, 10-19 students: 31% of classes etc.\n",
    "#this code is used to take the median of each bin, multiply it by the % its represented, and then summing all of \n",
    "#these values to calculate the average class size for each college\n",
    "classSizedf = pd.DataFrame(df.classSize.values.tolist(), index= df.index)\n",
    "#replace Nones and \"Not reported\" with NaN\n",
    "classSizedf = classSizedf.replace(\"Not reported\", np.nan)\n",
    "classSizedf.fillna(value=np.nan, inplace = True)\n",
    "#cleaning white space at beginning and end of lists, and splitting into elements\n",
    "classSizedf = classSizedf.apply(lambda x: x.str.strip())\n",
    "classSizedf = classSizedf.apply(lambda x: x.str.split(' '))\n",
    "\n",
    "#for most of the lists, the first element will be the bin (e.g. 2-9 students), and the third element will be the %.\n",
    "#these lists have a length of 5. The other lists be in the format [Over 100 students: 0% of classes] and have a \n",
    "#length of 6, so we can just get the second element and multiply it by the 4th.\n",
    "def getMedian(l):\n",
    "    if len(l) == 6:\n",
    "        return float(l[1].strip()) * float(l[3].strip('%'))/100\n",
    "    else:\n",
    "        return sum(map(float, l[0].split('-')))/2 * float(l[2].strip('%'))/100\n",
    "\n",
    "classSizeBins = classSizedf.applymap(lambda x: x if type(pd.isnull(x)) == bool else getMedian(x))\n",
    "classSizeBins['avgClassSize'] = (classSizeBins[0].fillna(0) + classSizeBins[1].fillna(0) + \n",
    "                                 classSizeBins[2].fillna(0) + classSizeBins[3].fillna(0) +\n",
    "                                 classSizeBins[4].fillna(0) + classSizeBins[5].fillna(0) +\n",
    "                                 classSizeBins[6].fillna(0))\n",
    "\n",
    "df['avgClassSize'] = classSizeBins['avgClassSize']\n",
    "df.avgClassSize.replace(0, np.nan, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 864,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing non breaking spaces, blank strings, and Not Reported/available with NaN\n",
    "#doing this again after I have dealt with all variables that were lists\n",
    "df = df.replace([\"\\u00a0\", \"Not reported\", 'Not available', ''], np.nan)\n",
    "df.fillna(value=np.nan, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 865,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check how many nulls are within each column. There are some columns which have 40%+ nulls, and so I have decided to\n",
    "#drop these variables, because it is hard to impute when there are such a large amount missing. undergradMen should\n",
    "#also be the complement of undergradWomen, and coed flag should be very highly correlated with the % of undergradWomen,\n",
    "#so dropping these variables.\n",
    "#dropping SATWriting because not many schools require this anymore, so there are a lot of null values, and \n",
    "#tuition, book, room, and other cost are components of total cost, so I am removing these variables too.\n",
    "\n",
    "df = df.drop(['averageSalary','sororities', 'pctEmployedin6Mo', 'pctAdvancedStudy', 'numFaculty',\n",
    "              'fraternities', 'coed', 'undergradMen', 'tuitionCost', 'bookCost', 'roomCost',\n",
    "              'otherCost', 'SATWriting'], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 866,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Private for-profit schools have a vastly different structure than private/public colleges, and since the number\n",
    "#of observations with an institution type of \"Private for-profit\" is only 11, I am dropping these observations.\n",
    "\n",
    "df = df[df.institutionType != \"Private for-profit\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 867,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for values with a range, take the average, else just return the value\n",
    "def getScore(s):\n",
    "    s = s.split(' ')[0]\n",
    "    if '-' in s:\n",
    "        return sum(map(float, s.split('-')))/2\n",
    "    else:\n",
    "        return float(s)\n",
    "\n",
    "df.ACT = df.ACT.apply(lambda x: x if pd.isnull(x) else getScore(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 868,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.SATMath = df.SATMath.apply(lambda x: x if pd.isnull(x) else getScore(x))\n",
    "df.SATReading = df.SATReading.apply(lambda x: x if pd.isnull(x) else getScore(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 869,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAT Scores investigation\n",
    "df[['SATMath', 'SATReading']].describe()\n",
    "df[df.SATReading > df.SATReading.quantile(0.95)][['url', 'SATReading']].sort_values(by = \"SATReading\", ascending = False)\n",
    "# average should be 465 for college at index 1610 (incorrectly stated on website, correct value is underneath)\n",
    "df.SATReading.loc[1610,] = 465\n",
    "#checked values that seemed like outliers, and imputed based on what the value should be\n",
    "\n",
    "df.SATMath.loc[633,] = 750\n",
    "df.SATMath.loc[370,] = 505\n",
    "df.SATMath.loc[[1718,1760],] = np.nan\n",
    "df.SATReading.loc[[435,1760],] = np.nan\n",
    "df.SATReading.loc[1787, ] = 570\n",
    "df.ACT.loc[435, ] = 22.5\n",
    "df.ACT.loc[1789, ] = 21.5\n",
    "df.ACT.loc[1413, ] = 23\n",
    "df.avgGPA.loc[176,] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 870,
   "metadata": {},
   "outputs": [],
   "source": [
    "#found two rows where the areaPop was pulling the incorrect information, set to nan.\n",
    "df[df.areaPop.apply(lambda x: False if pd.isnull(x) else x.isalpha())]\n",
    "df.areaPop.loc[1271,] = np.nan\n",
    "df.areaPop = df.areaPop.apply(lambda x: x if pd.isnull(x) else float(''.join([c for c in x if c.isnumeric()])))\n",
    "#found an outlier in town of Ypsilanti, Michigan. reassigned the area population to 2017 census value\n",
    "df[df.areaPop > df.areaPop.quantile(0.90)][['url', 'areaPop']].sort_values(by = \"areaPop\", ascending = False)\n",
    "df.areaPop.loc[1858,] = 21018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 871,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.avgAge = pd.to_numeric(df.avgAge)\n",
    "df.avgAward = df.avgAward.apply(lambda x: x if pd.isnull(x) else float(''.join([c for c in x if c.isnumeric()])))\n",
    "df.avgGPA = df.avgGPA.apply(lambda x: x if pd.isnull(x) else float(x.split(' ')[0]))\n",
    "df.avgIndebtness = df.avgIndebtness.apply(lambda x: x if pd.isnull(x) else float(''.join([c for c in x if c.isnumeric()])))\n",
    "df.campusSize = df.campusSize.apply(lambda x: x if pd.isnull(x) else float(''.join([c for c in x if c.isnumeric()])))\n",
    "df.numGrad = df.numGrad.apply(lambda x: x if pd.isnull(x) else float(''.join([c for c in x if c.isnumeric()])))\n",
    "df.numUndergrad = df.numUndergrad.apply(lambda x: x if pd.isnull(x) else float(''.join([c for c in x if c.isnumeric()])))\n",
    "df.pctInternationalStudents = df.pctInternationalStudents.apply(lambda x: x if pd.isnull(x) else float(x.split(' ')[0].strip('%'))/100)\n",
    "df.pctStudentsGraduatingin4Yrs = df.pctStudentsGraduatingin4Yrs.apply(lambda x: x if pd.isnull(x) else float(x.strip('%'))/100)\n",
    "df.pctWithLoans = df.pctWithLoans.apply(lambda x: x if pd.isnull(x) else float(x.strip('%'))/100)\n",
    "df.undergradWomen = df.undergradWomen.apply(lambda x: x if pd.isnull(x) else float(''.join(c for c in x if c not in '()').split(' ')[1].strip('%'))/100)\n",
    "df.admissionRate = df.admissionRate.apply(lambda x: x if pd.isnull(x) else float(x.split('%')[0])/100)\n",
    "df.institutionType = df.institutionType.apply(lambda x: x if pd.isnull(x) else 0 if x == \"Public\" else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 872,
   "metadata": {},
   "outputs": [],
   "source": [
    "#schoolid 763 and 682, 1670 got financial need % should be NaNs, since they have no denominator\n",
    "#row index of 86, 199, 1367\n",
    "df.gotFinancialNeed.loc[[86,199,1367]] = np.nan\n",
    "df.gotFinancialNeed = df.gotFinancialNeed.apply(lambda x: x if pd.isnull(x) else x.split(' ')[1])\n",
    "\n",
    "#school id 1486, 886, 187, 1125, 911, 652, 1308, 861, 888, 804 need to manually impute (they just didnt report the \n",
    "#% in the field that I scraped. I went back to the website and manually calculated the % for the list below.\n",
    "#these schools have the row index of 413, 929, 979, 1090, 1115, 1338, 1407, 1505, 1591,1845\n",
    "indexList = [413, 929, 979, 1090, 1115, 1338, 1407, 1505, 1591, 1845]\n",
    "valueList = [\"(99.7%)\", \"(99.4%)\", \"(99.6%)\", \"(99.8%)\", \"(96.3%)\", \"(98.2%)\", \n",
    "               \"(96.6%)\", \"(99.8%)\", \"(96.0%)\", \"(95.3%)\"]\n",
    "\n",
    "for i in range(len(indexList)):\n",
    "    df.gotFinancialNeed.loc[indexList[i]] = valueList[i]\n",
    "\n",
    "# #All the other school IDs that did not have a % were in fact 100% after taking a look at the website\n",
    "df.gotFinancialNeed.loc[[34,166,181,220,322,506,711,938,1206,1314,1498,1574,1596,1655,1714,1947]] = \"(100.0%)\"\n",
    "df.gotFinancialNeed = df.gotFinancialNeed.apply(lambda x: x if pd.isnull(x) else float(''.join(c for c in x if c not in '()').strip('%'))/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 873,
   "metadata": {},
   "outputs": [],
   "source": [
    "#priority housing should realistically mean that you get guaranteed housing barring any major issues, so \n",
    "#decided to group them together.\n",
    "df.freshmanHousingGuaranteed = df.freshmanHousingGuaranteed.apply(lambda x: x if pd.isnull(x) else 0 if x == \"Freshmen are not guaranteed housing\" else 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STILL TO CLEAN - on Hold.\n",
    "#sportsdiv for now - categorical \n",
    "#nearestAirport/bus/Train\n",
    "\n",
    "#nearestTransportation cleaning LATER\n",
    "\n",
    "#df.nearestAirport.apply(lambda x: x if pd.isnull(x) else x[3:10]).value_counts()\n",
    "#df.nearestAirport.apply(lambda x: False if pd.isnull(x) else x.isalpha())\n",
    "#df.nearestAirport[df.nearestAirport.apply(lambda x: False if pd.isnull(x) else x.split(' ')[0].isalpha())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating dataset where the NaNs are filled with the mean of the column, by the institutionType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 888,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.drop(['mascot','nearestAirport', 'nearestBus', 'nearestTrain', 'schoolColors', \n",
    "                'sportsDivision', 'classSize'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 896,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.groupby('institutionType', as_index = False).apply(lambda x: x.fillna(x.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 877,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PICKLING DF TO USE FOR REGRESSION MODELS\n",
    "pickle.dump(df,open('/Users/kstern/ds/metis/Kevin/Projects/Luther/data/collegeData.pickle','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 898,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PICKLING DF where NaNs are filled with means\n",
    "pickle.dump(df2,open('/Users/kstern/ds/metis/Kevin/Projects/Luther/data/collegeData2.pickle','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
